{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/iyanumanuel/spark/spark-3.0.3-bin-hadoop3.2/python/pyspark/__init__.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/22 00:57:29 WARN Utils: Your hostname, vmi641720.contaboserver.net resolves to a loopback address: 127.0.1.1; using 66.94.120.221 instead (on interface eth0)\n",
      "22/06/22 00:57:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/iyanumanuel/spark/spark-3.0.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/06/22 00:57:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-22 00:58:05--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-01.parquet\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.217.164.225\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.217.164.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11886281 (11M) [binary/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2021-01.parquet’\n",
      "\n",
      "fhv_tripdata_2021-0 100%[===================>]  11.33M  3.68MB/s    in 3.1s    \n",
      "\n",
      "2022-06-22 00:58:09 (3.68 MB/s) - ‘fhv_tripdata_2021-01.parquet’ saved [11886281/11886281]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-01.parquet\n",
    "\n",
    "#!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32645 fhv_tripdata_2021-01.parquet\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2021-01-01 01:27:00|2021-01-01 01:44:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2021-01-01 01:50:00|2021-01-01 02:07:00|        null|        null|   null|                B00009|\n",
      "|              B00013|2021-01-01 01:01:00|2021-01-01 02:51:00|        null|        null|   null|                B00013|\n",
      "|              B00037|2021-01-01 01:13:09|2021-01-01 01:21:26|        null|        72.0|   null|                B00037|\n",
      "|              B00037|2021-01-01 01:38:31|2021-01-01 01:53:44|        null|        61.0|   null|                B00037|\n",
      "|              B00037|2021-01-01 01:59:02|2021-01-01 02:08:05|        null|        71.0|   null|                B00037|\n",
      "|              B00037|2021-01-01 01:18:12|2021-01-01 01:30:04|        null|        91.0|   null|                B00037|\n",
      "|              B00037|2021-01-01 01:36:15|2021-01-01 01:45:08|        null|        39.0|   null|                B00037|\n",
      "|              B00037|2021-01-01 01:55:04|2021-01-01 02:13:02|        null|        37.0|   null|                B00037|\n",
      "|              B00037|2021-01-01 01:48:40|2021-01-01 02:12:02|        null|        39.0|   null|                B00037|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('fhv_tripdata_2021-01.parquet')\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B00009', pickup_datetime=datetime.datetime(2021, 1, 1, 1, 27), dropOff_datetime=datetime.datetime(2021, 1, 1, 1, 44), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00009'),\n",
       " Row(dispatching_base_num='B00009', pickup_datetime=datetime.datetime(2021, 1, 1, 1, 50), dropOff_datetime=datetime.datetime(2021, 1, 1, 2, 7), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00009'),\n",
       " Row(dispatching_base_num='B00013', pickup_datetime=datetime.datetime(2021, 1, 1, 1, 1), dropOff_datetime=datetime.datetime(2021, 1, 1, 2, 51), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00013'),\n",
       " Row(dispatching_base_num='B00037', pickup_datetime=datetime.datetime(2021, 1, 1, 1, 13, 9), dropOff_datetime=datetime.datetime(2021, 1, 1, 1, 21, 26), PUlocationID=None, DOlocationID=72.0, SR_Flag=None, Affiliated_base_number='B00037'),\n",
       " Row(dispatching_base_num='B00037', pickup_datetime=datetime.datetime(2021, 1, 1, 1, 38, 31), dropOff_datetime=datetime.datetime(2021, 1, 1, 1, 53, 44), PUlocationID=None, DOlocationID=61.0, SR_Flag=None, Affiliated_base_number='B00037')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(dispatching_base_num,StringType,true),StructField(pickup_datetime,TimestampType,true),StructField(dropOff_datetime,TimestampType,true),StructField(PUlocationID,DoubleType,true),StructField(DOlocationID,DoubleType,true),StructField(SR_Flag,IntegerType,true),StructField(Affiliated_base_number,StringType,true)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1842915578.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [10]\u001b[0;36m\u001b[0m\n\u001b[0;31m    .option(\"delimiter\",\"|\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "df.write.option(\"header\",True)\n",
    "        .option(\"delimiter\",\"|\")\n",
    "        .csv(\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: 1: No such file or directory\n",
      " 1154112  1154112 98801233 head.csv\n",
      " 1154112  1154112 98801233 total\n"
     ]
    }
   ],
   "source": [
    "!wc 1 head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv('head.csv', delimiter= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B00009                            object\n",
       "2021-01-01T01:27:00.000+01:00     object\n",
       "2021-01-01T01:44:00.000+01:00     object\n",
       "Unnamed: 3                       float64\n",
       "Unnamed: 4                       float64\n",
       "Unnamed: 5                       float64\n",
       "B00009.1                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B00009</th>\n",
       "      <th>2021-01-01T01:27:00.000+01:00</th>\n",
       "      <th>2021-01-01T01:44:00.000+01:00</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>B00009.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01T01:50:00.000+01:00</td>\n",
       "      <td>2021-01-01T02:07:00.000+01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01T01:01:00.000+01:00</td>\n",
       "      <td>2021-01-01T02:51:00.000+01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01T01:13:09.000+01:00</td>\n",
       "      <td>2021-01-01T01:21:26.000+01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01T01:38:31.000+01:00</td>\n",
       "      <td>2021-01-01T01:53:44.000+01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01T01:59:02.000+01:00</td>\n",
       "      <td>2021-01-01T02:08:05.000+01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B00009  2021-01-01T01:27:00.000+01:00  2021-01-01T01:44:00.000+01:00  \\\n",
       "0  B00009  2021-01-01T01:50:00.000+01:00  2021-01-01T02:07:00.000+01:00   \n",
       "1  B00013  2021-01-01T01:01:00.000+01:00  2021-01-01T02:51:00.000+01:00   \n",
       "2  B00037  2021-01-01T01:13:09.000+01:00  2021-01-01T01:21:26.000+01:00   \n",
       "3  B00037  2021-01-01T01:38:31.000+01:00  2021-01-01T01:53:44.000+01:00   \n",
       "4  B00037  2021-01-01T01:59:02.000+01:00  2021-01-01T02:08:05.000+01:00   \n",
       "\n",
       "   Unnamed: 3  Unnamed: 4  Unnamed: 5 B00009.1  \n",
       "0         NaN         NaN         NaN   B00009  \n",
       "1         NaN         NaN         NaN   B00013  \n",
       "2         NaN        72.0         NaN   B00037  \n",
       "3         NaN        61.0         NaN   B00037  \n",
       "4         NaN        71.0         NaN   B00037  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
